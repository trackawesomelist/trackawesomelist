# Awesome List Updates on Dec 14, 2023

2 awesome lists updated today.

[ğŸ  Home](/README.md) Â· [ğŸ” Search](https://www.trackawesomelist.com/search/) Â· [ğŸ”¥ Feed](https://www.trackawesomelist.com/rss.xml) Â· [ğŸ“® Subscribe](https://trackawesomelist.us17.list-manage.com/subscribe?u=d2f0117aa829c83a63ec63c2f&id=36a103854c) Â· [â¤ï¸  Sponsor](https://github.com/sponsors/theowenyoung)



## [1. Awesome Azure Openai Llm](/content/kimtth/awesome-azure-openai-llm/README.md)

### **RAG Pipeline & Advanced RAG**

*   Demystifying Advanced RAG Pipelines: An LLM-powered advanced RAG pipeline built from scratch [git (â­776)](https://github.com/pchunduri6/rag-demystified) \[19 Oct 2023]

### **Vector Database Comparison**

*   [Faiss](https://faiss.ai/): Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It is used as an alternative to a vector database in the development and library of algorithms for a vector database. It is developed by Facebook AI Research. [git (â­30k)](https://github.com/facebookresearch/faiss) \[Feb 2017]

### **Semantic Kernel** / **Azure AI Search**

*   Microsoft LangChain Library supports C# and Python and offers several features, some of which are still in development and may be unclear on how to implement. However, it is simple, stable, and faster than Python-based open-source software. The features listed on the link include: [Semantic Kernel Feature Matrix](https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages) / doc:[ref](https://learn.microsoft.com/en-us/semantic-kernel) / blog:[ref](https://devblogs.microsoft.com/semantic-kernel/) / [git](https://aka.ms/sk/repo) \[Feb 2023]

### **LangChain features and related libraries** / DSPy optimizer

*   [LangChain Expression Language](https://python.langchain.com/docs/guides/expression_language/): A declarative way to easily compose chains together \[Aug 2023]
*   [OpenGPTs (â­6.4k)](https://github.com/langchain-ai/opengpts): An open source effort to create a similar experience to OpenAI's GPTs \[Nov 2023]
*   [langflow (â­24k)](https://github.com/logspace-ai/langflow): LangFlow is a UI for LangChain, designed with react-flow. \[Feb 2023]
*   [Flowise (â­29k)](https://github.com/FlowiseAI/Flowise) Drag & drop UI to build your customized LLM flow \[Apr 2023]

### **Prompt Engineering** / **Prompt Template Language**

*   Power of Prompting

    *   [GPT-4 with Medprompt](https://arxiv.org/abs/2311.16452): GPT-4, using a method called Medprompt that combines several prompting strategies, has surpassed MedPaLM 2 on the MedQA dataset without the need for fine-tuning. [ref](https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/) \[28 Nov 2023]
    *   [promptbase (â­5.3k)](https://github.com/microsoft/promptbase): Scripts demonstrating the Medprompt methodology \[Dec 2023]

### **Prompt Guide & Leaked prompts** / **Prompt Template Language**

*   [Prompts for Education (â­1.5k)](https://github.com/microsoft/prompts-for-edu): Microsoft Prompts for Education \[Jul 2023]

### **RLHF (Reinforcement Learning from Human Feedback) & SFT (Supervised Fine-Tuning)** / **Llama Finetuning**

*   OpenAI Spinning Up in Deep RL!: An educational resource to help anyone learn deep reinforcement learning. [git (â­9.9k)](https://github.com/openai/spinningup) \[Nov 2018]

### **Quantization Techniques** / **Llama Finetuning**

*   bitsandbytes: 8-bit optimizers [git (â­5.9k)](https://github.com/TimDettmers/bitsandbytes) \[Oct 2021]

### **Other techniques and LLM patterns** / **Llama Finetuning**

*   [Mixture of experts models](https://mistral.ai/news/mixtral-of-experts/): Mixtral 8x7B: Sparse mixture of experts models (SMoE) [magnet](https://x.com/MistralAI/status/1706877320844509405?s=20) \[Dec 2023]
*   [Huggingface Mixture of Experts Explained](https://huggingface.co/blog/moe): Mixture of Experts, or MoEs for short \[Dec 2023]
*   [Simplifying Transformer Blocks](https://arxiv.org/abs/2311.01906): Simplifie Transformer. Removed several block components, including skip connections, projection/value matrices, sequential sub-blocks and normalisation layers without loss of training speed. \[3 Nov 2023]

### **Numbers LLM** / **GPT series release date**

*   [tiktoken (â­12k)](https://github.com/openai/tiktoken): BPE tokeniser for use with OpenAI's models. Token counting. \[Dec 2022]
*   [What are tokens and how to count them?](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them): OpenAI Articles
*   [Byte-Pair Encoding (BPE)](https://arxiv.org/abs/1508.07909): P.2015. The most widely used tokenization algorithm for text today. BPE adds an end token to words, splits them into characters, and merges frequent byte pairs iteratively until a stop criterion. The final tokens form the vocabulary for new data encoding and decoding. \[31 Aug 2015] / [ref](https://towardsdatascience.com/byte-pair-encoding-subword-based-tokenization-algorithm-77828a70bee0) \[13 Aug 2021]

### **Trustworthy, Safe and Secure LLM** / **GPT series release date**

*   [NeMo Guardrails (â­3.9k)](https://github.com/NVIDIA/NeMo-Guardrails): Building Trustworthy, Safe and Secure LLM Conversational Systems \[Apr 2023]
*   [Hallucination Leaderboard (â­1.1k)](https://github.com/vectara/hallucination-leaderboard/): Evaluate how often an LLM introduces hallucinations when summarizing a document. \[Nov 2023]

### **Large Language Model Is: Abilities** / **GPT series release date**

*   Math soving optimized LLM [WizardMath](https://arxiv.org/abs/2308.09583): \[[cnt](https://scholar.google.com/scholar?hl=en\&as_sdt=0%2C5\&q=arxiv%3A+2308.09583)]: Developed by adapting Evol-Instruct and Reinforcement Learning techniques, these models excel in math-related instructions like GSM8k and MATH. [git (â­9.2k)](https://github.com/nlpxucan/WizardLM) \[18 Aug 2023] / Math solving Plugin: [Wolfram alpha](https://www.wolfram.com/wolfram-plugin-chatgpt/)

### **Build an LLMs from scratch: picoGPT and lit-gpt** / **GPT series release date**

*   lit-gpt: Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. [git (â­9.4k)](https://github.com/Lightning-AI/lit-gpt) \[Mar 2023]
*   [pix2code (â­12k)](https://github.com/tonybeltramelli/pix2code): Generating Code from a Graphical User Interface Screenshot. Trained dataset as a pair of screenshots and simplified intermediate script for HTML, utilizing image embedding for CNN and text embedding for LSTM, encoder and decoder model. Early adoption of image-to-code. \[May 2017] -> [Screenshot to code (â­16k)](https://github.com/emilwallner/Screenshot-to-code): Turning Design Mockups Into Code With Deep Learning \[Oct 2017] [ref](https://blog.floydhub.com/turning-design-mockups-into-code-with-deep-learning/)

### **LLM Materials for East Asian Languages** / Japanese

*   [ãƒ–ãƒ¬ã‚¤ãƒ³ãƒ‘ãƒƒãƒ‰ç¤¾å“¡ãŒæŠ•ç¨¿ã—ãŸ Qiita è¨˜äº‹ã¾ã¨ã‚](https://blog.brainpad.co.jp/entry/2023/07/27/153055): ãƒ–ãƒ¬ã‚¤ãƒ³ãƒ‘ãƒƒãƒ‰ç¤¾å“¡ãŒæŠ•ç¨¿ã—ãŸ Qiita è¨˜äº‹ã¾ã¨ã‚ \[Jul 2023]
*   [New Era of Computing - ChatGPT ãŒã‚‚ãŸã‚‰ã—ãŸæ–°æ™‚ä»£](https://speakerdeck.com/dahatake/new-era-of-computing-chatgpt-gamotarasitaxin-shi-dai-3836814a-133a-4879-91e4-1c036b194718) \[May 2023]
*   [å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§å¤‰ã‚ã‚‹ ML ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º](https://speakerdeck.com/hirosatogamo/da-gui-mo-yan-yu-moderudebian-warumlsisutemukai-fa): ML system development that changes with large-scale language models \[Mar 2023]
*   [GPT-4 ç™»å ´ä»¥é™ã«å‡ºã¦ããŸ ChatGPT/LLM ã«é–¢ã™ã‚‹è«–æ–‡ã‚„æŠ€è¡“ã®æŒ¯ã‚Šè¿”ã‚Š](https://blog.brainpad.co.jp/entry/2023/06/05/153034): Review of ChatGPT/LLM papers and technologies that have emerged since the advent of GPT-4 \[Jun 2023]
*   [LLM ã‚’åˆ¶å¾¡ã™ã‚‹ã«ã¯ä½•ã‚’ã™ã‚‹ã¹ãã‹ï¼Ÿ](https://blog.brainpad.co.jp/entry/2023/06/08/161643): How to control LLM \[Jun 2023]
*   [1. ç”Ÿæˆ AI ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã§ãã‚‹ã“ã¨](https://blog.brainpad.co.jp/entry/2023/06/06/160003): What can be done with multimodal models of generative AI [2. ç”Ÿæˆ AI ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹æŠ€è¡“èª¿æŸ»](https://blog.brainpad.co.jp/entry/2023/10/18/153000) \[Jun 2023]
*   [LLM ã®æ¨è«–ã‚’åŠ¹ç‡åŒ–ã™ã‚‹é‡å­åŒ–æŠ€è¡“èª¿æŸ»](https://blog.brainpad.co.jp/entry/2023/09/01/153003): Survey of quantization techniques to improve efficiency of LLM reasoning \[Sep 2023]
*   [LLM ã®å‡ºåŠ›åˆ¶å¾¡ã‚„æ–°ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦](https://blog.brainpad.co.jp/entry/2023/09/08/155352): About LLM output control and new models \[Sep 2023]
*   [Azure OpenAI ã‚’æ´»ç”¨ã—ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ (â­264)](https://github.com/Azure-Samples/jp-azureopenai-samples): æ—¥æœ¬ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆ ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ \[Jun 2023]
*   [ç”Ÿæˆ AIãƒ»LLM ã®ãƒ„ãƒ¼ãƒ«æ‹¡å¼µã«é–¢ã™ã‚‹è«–æ–‡ã®å‹•å‘èª¿æŸ»](https://blog.brainpad.co.jp/entry/2023/09/22/150341): Survey of trends in papers on tool extensions for generative AI and LLM \[Sep 2023]
*   [LLM ã®å­¦ç¿’ãƒ»æ¨è«–ã®åŠ¹ç‡åŒ–ãƒ»é«˜é€ŸåŒ–ã«é–¢ã™ã‚‹æŠ€è¡“èª¿æŸ»](https://blog.brainpad.co.jp/entry/2023/09/28/170010): Technical survey on improving the efficiency and speed of LLM learning and inference \[Sep 2023]

### **Learning and Supplementary Materials** / Korean

*   [gpt4free (â­60k)](https://github.com/xtekky/gpt4free) for educational purposes only \[Mar 2023]
*   [IbrahimSobh/llms (â­266)](https://github.com/IbrahimSobh/llms): Language models introduction with simple code. \[Jun 2023]
*   [DeepLearning.ai Short courses](https://www.deeplearning.ai/short-courses/): DeepLearning.ai Short courses \[2023]
*   [Deep Learning cheatsheets for Stanford's CS 230 (â­6.3k)](https://github.com/afshinea/stanford-cs-230-deep-learning/tree/master/en): Super VIP Cheetsheet: Deep Learning \[Nov 2019]
*   [Best-of Machine Learning with Python (â­16k)](https://github.com/ml-tooling/best-of-ml-python):ğŸ†A ranked list of awesome machine learning Python libraries. \[Nov 2020]

### **Section 10: General AI Tools and Extensions** / **OSS Alternatives for OpenAI Code Interpreter (aka. Advanced Data Analytics)**

*   [Vercel AI](https://sdk.vercel.ai/) Vercel AI Playground / Vercel AI SDK [git (â­9.1k)](https://github.com/vercel/ai) \[May 2023]
*   [Quora Poe](https://poe.com/login) A chatbot service that gives access to GPT-4, gpt-3.5-turbo, Claude from Anthropic, and a variety of other bots. \[Feb 2023]

### **Section 11: Datasets for LLM Training** / **OSS Alternatives for OpenAI Code Interpreter (aka. Advanced Data Analytics)**

*   [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/): The Stanford Question Answering Dataset (SQuAD), a set of Wikipedia articles, 100,000+ question-answer pairs on 500+ articles. \[16 Jun 2016]
*   [å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¾ã¨ã‚](https://note.com/npaka/n/n686d987adfb1): å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¾ã¨ã‚ \[Apr 2023]

## [2. Static Analysis](/content/analysis-tools-dev/static-analysis/README.md)

### Programming Languages / [Other](#other-1)

*   [JET (â­726)](https://github.com/aviatesk/JET.jl) â€” Static type inference system to detect bugs and type instabilities.

---

- Prev: [Dec 15, 2023](/content/2023/12/15/README.md)
- Next: [Dec 13, 2023](/content/2023/12/13/README.md)